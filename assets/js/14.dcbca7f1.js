(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{503:function(t,s,a){t.exports=a.p+"assets/img/mrs_excel.1c0b718c.png"},533:function(t,s,a){"use strict";a.r(s);var n=a(27),p=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"_10-倍程序员系列-⭐脚本的魅力-内含-js-写爬虫、python-骚操作等实用代码"}},[t._v("[10 倍程序员系列] ⭐脚本的魅力，内含 js 写爬虫、python 骚操作等实用代码")]),t._v(" "),n("h2",{attrs:{id:"零、内容简介"}},[t._v("零、内容简介")]),t._v(" "),n("p",[t._v("将脚本用好能给工作带来事半功倍的效果，本文的内容主要涉及三个脚本工具："),n("code",[t._v("js")]),t._v("、"),n("code",[t._v("awk")]),t._v("、"),n("code",[t._v("python")]),t._v("， 主题如下：")]),t._v(" "),n("ul",[n("li",[t._v("使用 "),n("code",[t._v("js")]),t._v(" 在浏览器控制台写爬虫。")]),t._v(" "),n("li",[t._v("使用 "),n("code",[t._v("shell")]),t._v(" 统计数据。")]),t._v(" "),n("li",[t._v("使用 "),n("code",[t._v("python")]),t._v(" 进行 "),n("code",[t._v("redis")]),t._v("、"),n("code",[t._v("rabbitmq")]),t._v(" 运维。")]),t._v(" "),n("li",[t._v("使用 "),n("code",[t._v("python")]),t._v(" 生成 "),n("code",[t._v("mysql 数据字典")]),t._v("。")])]),t._v(" "),n("p",[t._v("话不多说，直接进入主题。")]),t._v(" "),n("h2",{attrs:{id:"一、使用-js-在浏览器控制台写爬虫"}},[t._v("一、使用 js 在浏览器控制台写爬虫")]),t._v(" "),n("h3",{attrs:{id:"_1-1-抓取数据"}},[t._v("1.1 抓取数据")]),t._v(" "),n("p",[t._v("使用 js 在浏览器控制台写爬虫的优势是不需要模拟浏览器请求、登录信息、基本不会被反爬虫技术禁止访问等，劣势是数据不易保存，如果爬虫是一次性的，且抓取的数据不多，使用 js 可以在几分钟就写好爬虫，至于获取的数据可以采取复制为 json 的方式导出，json 数据可以再进一步转换为易于阅读的 excel 等数据，读完这个章节你将掌握如何把复杂 json 转换为 excel 平面数据。")]),t._v(" "),n("p",[t._v("下面以获取某网站 gitlab 合并请求数据为例讲解整个数据抓取流程。")]),t._v(" "),n("p",[t._v("需求是获取所有 gitlab 项目的合并请求数据，项目 id 列表事先已经知道，代码如下：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" ids "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 项目id")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" mrs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 数据结果")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("idx")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idx "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" ids"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fetch")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://xxx.com/gitlab/projects/"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n        ids"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("idx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/getMergeRequests?order_by=updated_at&page=1&per_page=100&state=all"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" credentials"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"same-origin"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("then")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("res")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("json")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("then")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("r")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("r"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("status "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"success"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          mrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("r"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("merge_requests"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ids"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("idx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" failed"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idx "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 为了让请求串行执行，所以这里采用回调递归调用")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"done"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开始抓取")]),t._v("\n")])])]),n("p",[t._v("短短几行代码就完成了数据的抓取，整个编码过程只需要 "),n("code",[t._v("5")]),t._v(" 分钟左右。")]),t._v(" "),n("p",[t._v("抓取之后，数据都存储在 mrs 变量中，直接在控制台输入 "),n("code",[t._v("mrs")]),t._v(" ，右键选择拷贝 json 数据，新建一个 "),n("code",[t._v("mrs.json")]),t._v(" 文件将其保存起来即可。")]),t._v(" "),n("h3",{attrs:{id:"_1-2-转换数据"}},[t._v("1.2 转换数据")]),t._v(" "),n("p",[t._v("接下来将 json 数据转换为 excel。")]),t._v(" "),n("p",[t._v("方案 1，使用 "),n("code",[t._v("pandas")]),t._v("：")]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas\npandas"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mrs.json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_excel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mrs.xlsx"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("如果数据结构是下面这类简单 json 使用这两行脚本即可。")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"title"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"标题"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"content"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"内容"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),n("p",[t._v("若数据结构较复杂，列表对象中含有子对象，例如：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"title"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"标题"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"content"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"内容"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"detail"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"createBy"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"张三"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),n("p",[t._v("此时需要编码展开子对象，我们这里使用方案 2。")]),t._v(" "),n("p",[t._v("方案 2，使用 excel 导入 + "),n("code",[t._v("Power Query M 公式语言")]),t._v("转换数据。")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("首先导入 JSON 数据。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(503),alt:"excel导入"}})])]),t._v(" "),n("li",[n("p",[t._v("在 Power Query 的高级编辑器中，修改 "),n("code",[t._v("Power Query M 公式语言")]),t._v(" 脚本展开 json 数据。")])])]),t._v(" "),n("div",{staticClass:"language-cs extra-class"},[n("pre",{pre:!0,attrs:{class:"language-cs"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" responseJson "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Document")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("File"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Contents")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:\\mrs.json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nheaders "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v("\n allHeaders "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Combine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Transform")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("responseJson"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("FieldNames"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n uniqueHeaders "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Distinct")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("allHeaders"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v("\n uniqueHeaders"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n testTable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("FromRecords")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("responseJson"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MissingField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UseNull"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v("\n testTable\n")])])]),n("p",[t._v("这样就完成了数据的转换，后续再生成数据图表或导入数据库都非常方便。")]),t._v(" "),n("p",[t._v("这部分内容的重点在于要灵活使用各种工具以快速得到想要的结果。")]),t._v(" "),n("h2",{attrs:{id:"二、使用-shell-统计数据"}},[t._v("二、使用 shell 统计数据")]),t._v(" "),n("p",[t._v("需求：在上百个 Java 代码仓库中统计单元测试方法的数量。")]),t._v(" "),n("p",[t._v("我们以这个例子来看看 "),n("code",[t._v("awk")]),t._v(" 的用法。")]),t._v(" "),n("p",[t._v("说明：这个统计方法只是简单查看单元测试方法数量，不涉及单元测试覆盖率等。")]),t._v(" "),n("p",[t._v("步骤如下：")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("首先本地含有所有的代码仓库，cd 到代码仓库根目录。")])]),t._v(" "),n("li",[n("p",[t._v("使用以下命令统计每个仓库的单元测试方法数量。")])])]),t._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("find")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(".")]),t._v(" -name "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'*Test.java'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("xargs")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("grep")]),t._v(" -i "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'@Test[^a-z]'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" -F / "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{count[$3]++;} END {for(i in count) {print i,count[i]}}'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" clip.exe\n")])])]),n("p",[t._v("注意：该命令运行在 "),n("code",[t._v("WSL")]),t._v("，所以可以在管道命令中包含 windows 命令。")]),t._v(" "),n("p",[t._v("命令说明：")]),t._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("find")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(".")]),t._v(" -name "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'*Test.java'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("xargs")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("grep")]),t._v(" -i "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'@Test[^a-z]'")]),t._v("\n")])])]),n("p",[t._v("找到所有 Test.java 结尾的文件，在文件中查找仅包含 @Test 的行，这一步的输出结果如下：")]),t._v(" "),n("div",{staticClass:"language-txt extra-class"},[n("pre",{pre:!0,attrs:{class:"language-txt"}},[n("code",[t._v("./project/repository1/module/src/.../xxx.java: @Test\n./project/repository2/module/src/.../xxx.java: @Test\n./project/repository3/module/src/.../xxx.java: @Test\n...\n")])])]),n("p",[t._v("根据这个数据模式，再使用 awk 编写脚本进行数据分析。")]),t._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" -F / "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{count[$3]++;} END {for(i in count) {print i,count[i]}}'")]),t._v("\n")])])]),n("p",[t._v("awk 脚本中指定 / 为分隔符，第三位为仓库名称，使用仓库名称进行分组，最后输出仓库名称和分组数量。")]),t._v(" "),n("p",[t._v("输出结果：")]),t._v(" "),n("div",{staticClass:"language-txt extra-class"},[n("pre",{pre:!0,attrs:{class:"language-txt"}},[n("code",[t._v("repository1 5\nrepository2 10\nrepository3 7\n...\n")])])]),n("p",[t._v("最后我们利用管道 "),n("code",[t._v("| clip.exe")]),t._v(" 将其拷贝到剪切板，再导入 excel 即可。")]),t._v(" "),n("h2",{attrs:{id:"三、使用-python-进行-redis、rabbitmq-运维"}},[t._v("三、使用 python 进行 redis、rabbitmq 运维")]),t._v(" "),n("h3",{attrs:{id:"_3-1-扫描-redis"}},[t._v("3.1 扫描 redis")]),t._v(" "),n("p",[t._v("当 redis 内存过期速度赶不上内存增长，会导致 redis 内存占用越来越大，我们可以调整 redis 清理频率，也可以手动扫描 redis 来触发内存清理。")]),t._v(" "),n("p",[t._v("使用 python 执行以下代码即可，真是 "),n("code",[t._v("人生苦短，我用 python")]),t._v("。")]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" redis\nr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" redis"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Redis"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" r"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scan"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    t "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" r"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scan"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"_3-2-rabbitmq-消息队列转发"}},[t._v("3.2 rabbitmq 消息队列转发")]),t._v(" "),n("p",[t._v("rabbitmq 上有消息队列转发的插件，但如果是云服务，通常无法使用该插件，此时用 python 写点转发脚本也是易事。")]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pika\n\nconnection "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pika"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BlockingConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pika"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ConnectionParameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("host"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ip'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" port"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5672")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" virtual_host"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("                                 credentials"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("pika"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PlainCredentials"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'account'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'password'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nchannel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" connection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("channel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("backcall")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" method"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 转发")]),t._v("\n    channel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("basic_publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("exchange"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'exchange'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" routing_key"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'routing_key'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" body"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nchannel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("basic_consume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'原队列'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("backcall"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nchannel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start_consuming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"四、使用-python-生成-mysql-数据字典"}},[t._v("四、使用 python 生成 mysql 数据字典")]),t._v(" "),n("p",[t._v("生成数据字典的工具有很多，但往往生成的数据字典不易修改，试试用 python 生成 markdown 格式的数据字典如何？")]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" mysql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connector\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" importlib\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("generate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("database_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    生成数据库字典表\n    """')]),t._v("\n    importlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("reload")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用前修改配置")]),t._v("\n    conn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mysql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connector"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        host"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'localhost'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        port"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3306'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        user"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        password"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        use_pure"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    cursor "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"SELECT TABLE_NAME, TABLE_COMMENT FROM information_schema.TABLES WHERE table_type='BASE TABLE' AND TABLE_SCHEMA='%s'\"")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" database_name\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    tables "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetchall"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    markdown_table_header "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\\n\\n\\n### %s (%s) \\n| 序号 | 字段名称 | 数据类型 | 是否为空 | 字段说明 |\\n| :--: |----| ---- | ---- | ---- |\\n"""')]),t._v("\n    markdown_table_row "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""| %s | %s | %s | %s | %s |"""')]),t._v("\n\n    f "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dict/'")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("database_name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.md'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"utf-8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tables"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n        cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SELECT ORDINAL_POSITION, COLUMN_NAME, COLUMN_TYPE, IS_NULLABLE, COLUMN_COMMENT "')]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"FROM information_schema.COLUMNS WHERE TABLE_SCHEMA='%s' AND TABLE_NAME='%s'\"")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                database_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        tmp_table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetchall"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" markdown_table_header "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" remove_newline"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" col "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tmp_table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            colf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("col"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            colf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("col"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mysql 高级版本需要解码，代码有点丑，临时性的，能用就行")]),t._v("\n            colf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("col"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("remove_newline"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("markdown_table_row "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        f"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("writelines"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    f"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("remove_newline")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    去除文本中的换行符号\n    """')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" text"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\r"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'__main__'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    conn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mysql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connector"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        host"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'localhost'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        port"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3306'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        user"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        password"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        use_pure"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    cursor "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SHOW DATABASES"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    dbs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetchall"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" db "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" dbs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        generate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    cursor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"五、后记"}},[t._v("五、后记")]),t._v(" "),n("p",[t._v("本篇文章内容比较杂，这些脚本不能说非常优美，但写起来确实是非常的高效，能够快速地完成需求，当我们把这些工具掌握的同时，偶尔发挥下想象力，必然能够体会到编程的乐趣和代码的魅力。")])])}),[],!1,null,null,null);s.default=p.exports}}]);